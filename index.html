<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Tahira Shehzadi</title>
    <meta name="description" content="Academic website of Tahira Shehzadi">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@400;500&display=swap">
    <link rel="stylesheet" href="style.css">
    <link rel="icon" type="image/png" href="icons/favicon.png">
  </head>
  <body>
    <div class="menu">
      <a href="#home">Home</a> &nbsp;&nbsp;&nbsp;
      <a href="#bio">Bio</a> &nbsp;&nbsp;&nbsp;
      <a href="#projects">Projects</a> &nbsp;&nbsp;&nbsp;
      <a href="#publications">Publications</a> &nbsp;&nbsp;&nbsp;
      <a href="#services">Services/Honors</a>
    </div>

<script>
function openBibtex() {
  document.getElementById("bibModal").style.display = "flex";
}
function closeBibtex() {
  document.getElementById("bibModal").style.display = "none";
}
function copyBib() {
  const bib = document.getElementById("bib").innerText;
  navigator.clipboard.writeText(bib);
  alert("BibTeX copied to clipboard!");
}
</script>

    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr id="home">
              <td style="padding:20px;width:67%;vertical-align:middle">
                <span class="name">Tahira Shehzadi</span>
                <p class="information">
                  Machine Learning Engineer at <a href="https://av.dfki.de/">DFKI</a>
                  and Ph.D. Candidate at <a href="https://rptu.de/">RPTU</a>
                </p>
                <p class="information">
                  <a href="mailto:tahirashehzadi9@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="CV-Tahira.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=-QzlQU8AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/tahira_31">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/tahirashehzadi">GitHub</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/tahira45/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:20px;width:33%;vertical-align:middle">
                <img class="dp" src="figures/Tahira.jpeg" alt="Profile photo">
              </td>
            </tr>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr id="bio">
              <td style="padding:20px;width:100%;vertical-align:middle">   
                <span class="section">About Me</span>
                <p class="bio">
                  I am a Machine Learning Engineer at the German Research Center for Artificial Intelligence (<a href="https://av.dfki.de/">DFKI</a>) and a PhD Candidate in Computer Science at RPTU Kaiserslauternâ€“Landau, supervised by Prof. Dr. Didier Stricker. My research advances robust and efficient visual perception, with a focus on semi-supervised learning, document intelligence, and object detection in challenging and low-annotation environments. My work has resulted in first-author publications at premier venues including CVPR, ICCV and ICDAR.
                  </p><p class="bio">
                  At DFKI, I lead research across multiple large-scale applied AI projects including semi-supervised object detection for complex 2D environments, a high-precision multimodal system for document layout analysis under the LUMINOUS project, and medical anomaly detection pipelines for the AIRISE initiative. I also completed an Applied AI Scientist internship at <a href="https://www.tensorlake.ai">Tensorlake</a>, San Francisco, where I worked on document intelligence systems, led VLM integration for document analysis, and developed data generation and post-processing pipelines for improving document layout, OCR accuracy, and strikethrough detection.
                  My research focuses on multimodal perception, data-efficient learning, and transformer architectures, with a long-term goal of enabling agentic AI systems that can autonomously understand, reason, and act based on visual information.
                  </p>
              </td>
            </tr>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr id="projects">
              <td style="padding:20px;width:100%;vertical-align:middle">
                <span class="section">Projects</span>

                 <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/Generic.gif" alt="Generic Object Detection">
                        <br>
                        <em><b>Target:</b> Small, Occluded, and Rare Objects</em>
                      </td>
                      <td>
                        <papertitle>Detection in Challenging Visual Environments</papertitle>
                        This project focuses on improving detection reliability for objects that are small, heavily occluded, or belong to visually rare categories. Traditional detectors often struggle when objects occupy only a few pixels, appear partially hidden, or lack strong representation in the training distribution. The system enhances spatial reasoning for dense scenes, recovers obscured object cues using contextual priors, and stabilizes category confidence for infrequent visual classes. This results in consistent performance across crowded environments, long-tail distributions, and real-world edge cases where conventional object detectors tend to fail.
                        </td>
                    </tr>
                  </table>

                  <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/DLA.gif" alt="Document Layout Analysis" style="width:180px; height:auto;">
                        <br>
                        <em><b>Target: </b>Document parsing</em>
                      </td>
                      <td>
                        <papertitle>Document Layout Analsis in Challenging Visual Environments</papertitle>
                        This project focuses on improving detection reliability in complex document images containing diverse and densely arranged visual components. The system enhances spatial reasoning for dense layouts, integrates contextual priors to improve structural coherence, and stabilizes category confidence for components that typically challenge OCR and downstream document understanding. Beyond conventional layout elements such as text blocks, tables, figures, and forms, the pipeline supports citation extraction, handwritten and digital signature detection, strikethrough identification and removal, stamp and watermark localization, and other fine-grained document objects that are crucial for legal, academic, and financial document processing. The approach delivers robust and consistent performance across real-world conditions, long-tail distributions, and document edge cases where traditional parsers and rule-based detectors tend to break.
                        </td>
                    </tr>
                  </table> 

           
                </div>
              </td>
            </tr>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr id="publications">
              <td style="padding:0 20px 20px 20px;width:100%;vertical-align:middle">
                <span class="section">Selected Publications <a href="https://scholar.google.com/citations?user=0CN11t4AAAAJ&hl=en">[Google Scholar]</a></span>

                 <div class="paper" style="background-color: #ffffd0">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/STEP.png" alt="STEP-DETR">
                      </td>
                      <td>
                        <papertitle>STEP-DETR: Advancing DETR-based Semi-Supervised Object Detection with Super Teacher and Pseudo-Label Guided Text Queries</papertitle>
                        <strong>T. Shehzadi</strong>, K.A.Hashmi, S.Sarode, D.Stricker, M.Z.Afzal
                        <br>
                        <em>ICCV</em>, 2025
                        <br>
                        <a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Shehzadi_STEP-DETR_Advancing_DETR-based_Semi-Supervised_Object_Detection_with_Super_Teacher_and_ICCV_2025_paper.pdf">Paper</a> /
                        <a href="https://openaccess.thecvf.com/content/ICCV2025/supplemental/Shehzadi_STEP-DETR_Advancing_DETR-based_ICCV_2025_supplemental.pdf">Supplementary</a> /
                        <a href="https://iccv.thecvf.com/media/iccv-2025/Slides/1214_8PMPvKr.pdf">Slides</a> /
                        <a href="https://iccv.thecvf.com/media/PosterPDFs/ICCV%202025/1214.png?t=1758726975.4345603">Poster</a> /
                        <a href="javascript:void(0)" onclick="openBibtex()" style="color:#1a73e8; text-decoration:none; margin-left:6px;">
                        BibTeX
                        </a>
                        <!-- Popup Modal -->
                        <div id="bibModal" style="display:none;position:fixed;top:0; left:0; width:100%; height:100%;background:rgba(0,0,0,0.6);align-items:center; justify-content:center;z-index:1000;">
                          <div style="background:white; padding:20px; border-radius:8px; max-width:700px; width:90%; position:relative;">
                            
                            <!-- Close button (top-right, small light grey) -->
                            <span onclick="closeBibtex()" style="
                              position:absolute; top:8px; right:12px;
                              cursor:pointer; font-size:20px; color:#b3b3b3;">
                              &times;
                            </span>
                        
                            <!-- BibTeX text -->
                            <pre id="bib" style="white-space:pre-wrap; font-family:monospace; margin:0; text-align:left;">
                            @InProceedings{Shehzadi_2025_ICCV,
                              author    = {Shehzadi, Tahira and Hashmi, Khurram Azeem and Sarode, Shalini and Stricker, Didier and Afzal, Muhammad Zeshan},
                              title     = {STEP-DETR: Advancing DETR-based Semi-Supervised Object Detection with Super Teacher and Pseudo-Label Guided Text Queries},
                              booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
                              month     = {October},
                              year      = {2025},
                              pages     = {3069-3079}
                            }
                            </pre>

                        
                            <!-- Copy button (bottom-left) -->
                            <button onclick="copyBib()" style="
                              margin-top:10px; cursor:pointer; padding:5px 12px;
                              background:white; border:1px solid #b3b3b3; border-radius:4px;">
                              ðŸ“‹ Copy
                            </button>
                        
                          </div>
                        </div>
              
                      </td>
                    </tr>
                  </table>
                </div>
                
                <div class="paper" style="background-color: #ffffd0">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/sparse_semidetr.jpeg" alt="Sparse Semi-DETR">
                      </td>
                      <td>
                        <papertitle>Sparse Semi-DETR: Sparse Learnable Queries for Semi-Supervised Object Detection</papertitle>
                        <strong>T. Shehzadi</strong>, K.A.Hashmi, D.Stricker, M.Z.Afzal
                        <br>
                        <em>CVPR</em>, 2024
                        <br>
                        <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Shehzadi_Sparse_Semi-DETR_Sparse_Learnable_Queries_for_Semi-Supervised_Object_Detection_CVPR_2024_paper.pdf">Paper</a> /
                        <a href="https://www.youtube.com/watch?v=lCjCveKC8ys&ab_channel=TahiraShehzadi">Video</a> /
                        <a href="https://openaccess.thecvf.com/content/CVPR2024/supplemental/Shehzadi_Sparse_Semi-DETR_Sparse_CVPR_2024_supplemental.pdf">Supplementary</a> /
                        <a href="https://cvpr.thecvf.com/media/cvpr-2024/Slides/30138.pdf">Slides</a> /
                        <a href="https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30138.png?t=1717582596.821112">Poster</a>
                      </td>
                    </tr>
                  </table>
                </div>
               

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/transformer_OD_survey.png" alt="Transformer OD Survey">
                      </td>
                      <td>
                        <papertitle>Object Detection with Transformers: A Review</papertitle>
                        <strong>T. Shehzadi</strong>, K.A.Hashmi, D.Stricker, M.Z.Afzal
                        <br>
                        <em>Sensors</em>, 2025
                        <br>
                        <a href="https://www.mdpi.com/1424-8220/25/19/6025">Paper</a> /
                        <a href="https://github.com/mindgarage-shan/transformer_object_detection_survey">Code</a>
                      </td>
                    </tr>
                  </table>
                </div>

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/SemiTabDETR.png" alt="SemiTabDETR">
                      </td>
                      <td>
                        <papertitle>SemiTabDETR: End-to-End Semi-Supervised Table Detection with Transformer-based Enhanced Query Approach</papertitle>
                        <strong>T. Shehzadi</strong>, D.Stricker, M.Z.Afzal
                        <br>
                        <em>ICDAR</em>, 2025
                        <br>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-032-04614-7_15">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/Additive.png" alt="Additive Attention">
                      </td>
                      <td>
                        <papertitle>Efficient Additive Attention for Transformer-based Semi-supervised Document Layout Analysis</papertitle>
                        <strong>T. Shehzadi</strong>, I.Ifza, D.Stricker, M.Z.Afzal
                        <br>
                        <em>ICCV Workshop</em>, 2025
                        <br>
                        <a href="https://openaccess.thecvf.com/content/ICCV2025W/WiCV/papers/Shehzadi_Efficient_Additive_Attention_for_Transformer-based_Semi-supervised_Document_Layout_Analysis_ICCVW_2025_paper.pdf">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>


                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/ClassroomKD.png" alt="ClassroomKD">
                      </td>
                      <td>
                        <papertitle>Classroom-Inspired Multi-mentor Distillation with Adaptive Learning Strategies</papertitle>
                        S.Sarode, M.S.Khan,<strong>T. Shehzadi</strong>, D.Stricker, M.Z.Afzal
                        <br>
                        <em>IntelliSys</em>, 2025
                        <br>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-99965-9_19">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/DocSemi.png" alt="DocSemi">
                      </td>
                      <td>
                        <papertitle>DocSemi: Efficient Document Layout Analysis with Guided Queries</papertitle>
                        <strong>T. Shehzadi</strong>, I.Ifza, D.Stricker, M.Z.Afzal
                        <br>
                        <em>ICCV Workshop</em>, 2025
                        <br>
                        <a href="https://openaccess.thecvf.com/content/ICCV2025W/VisionDocs/papers/Shehzadi_DocSemi_Efficient_Document_Layout_Analysis_with_Guided_Queries_ICCVW_2025_paper.pdf">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/FD-SSD.png" alt="FD-SSD">
                      </td>
                      <td>
                        <papertitle>FD-SSD: Semi-supervised Detection of Bone Fenestration and Dehiscence in Intraoral Images</papertitle>
                         <strong>T. Shehzadi</strong>, I.Ifza, D.Stricker, M.Z.Afzal
                        <br>
                        <em>MIUA</em>, 2025
                        <br>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-98691-8_1">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/Hybrid-DETR.png" alt="Hybrid">
                      </td>
                      <td>
                        <papertitle>A Hybrid Approach for Document Layout Analysis in Document images</papertitle>
                        <strong>T. Shehzadi</strong>, D.Stricker, M.Z.Afzal
                        <br>
                        <em>ICDAR</em>, 2024
                        <br>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-70546-5_2">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>
                
                 <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/SAM.png" alt="SAM">
                      </td>
                      <td>
                        <papertitle>Towards End-to-End Semi-Supervised Table Detection with Semantic Aligned Matching Transformer</papertitle>
                        <strong>T. Shehzadi</strong>, S.Sarode, D.Stricker, M.Z.Afzal
                        <br>
                        <em>ICDAR</em>, 2024
                        <br>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-70549-6_18">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>
                
                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/BankCheck.png" alt="BankCheck">
                      </td>
                      <td>
                        <papertitle>Enhanced Bank Check Security: Introducing a Novel Dataset and Transformer-Based Approach for Detection and Verification</papertitle>
                        M.S.Khan*, <strong>T. Shehzadi*</strong>, R.Noor, D.Stricker, M.Z.Afzal
                        <br>
                        <em>ICDAR Workshop</em>, 2024
                        <br>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-70442-0_3">Paper</a> /
                        <a href="https://github.com/tahirashehzadi/bank-check-security/blob/main/README.md">Code</a> 
                      </td>
                    </tr>
                  </table>
                </div>

                 <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/IJDAR24.png" alt="IJDAR">
                      </td>
                      <td>
                        <papertitle>End-to-End Semi-Supervised approach with Modulated Object Queries for Table Detection in Documents</papertitle>
                        I.Ehsan,<strong>T. Shehzadi</strong>, D.Stricker, M.Z.Afzal
                        <br>
                        <em>IJDAR</em>, 2024
                        <br>
                        <a href="https://link.springer.com/article/10.1007/s10032-024-00471-0">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/UnSupDLA.png" alt="UnSupDLA">
                      </td>
                      <td>
                        <papertitle>UnSupDLA: Towards Unsupervised Document Layout Analysis</papertitle>
                        T.Sheikh*, <strong>T. Shehzadi*</strong>, R.Noor, D.Stricker, M.Z.Afzal
                        <br>
                        <em>ICDAR Workshop</em>, 2024
                        <br>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-70442-0_9">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/Semi-Review.png" alt="Semi-Review">
                      </td>
                      <td>
                        <papertitle>Semi-Supervised Object Detection: A Survey on Progress from CNN to Transformer</papertitle>
                        <strong>T. Shehzadi</strong>, I.Ifza, D.Stricker, M.Z.Afzal
                        <br>
                        <em>arXiv</em>, 2024
                        <br>
                        <a href="https://arxiv.org/pdf/2407.08460">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/Def-Semi.png" alt="Def-Semi">
                      </td>
                      <td>
                        <papertitle>Towards End-to-End Semi-Supervised Table Detection with Deformable Transformer</papertitle>
                        <strong>T. Shehzadi</strong>, K.A.Hashmi, M.Liwicki, D.Stricker, M.Z.Afzal
                        <br>
                        <em>ICDAR</em>, 2023
                        <br>
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-41679-8_4">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

               
                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/FloorPlan.png" alt="FloorPlan">
                      </td>
                      <td>
                        <papertitle>Mask-Aware Semi-Supervised Object Detection in Floor Plans</papertitle>
                        <strong>T. Shehzadi</strong>, K.A.Hashmi, D.Stricker, M.Z.Afzal
                        <br>
                        <em>Sensors</em>, 2022
                        <br>
                        <a href="https://www.mdpi.com/2076-3417/12/19/9398">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>


                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/Traffic.png" alt="Traffic">
                      </td>
                      <td>
                        <papertitle>Geometric features and traffic dynamic analysis on 4-leg intersections</papertitle>
                        W.Saeed, M.S.Saleh, M.N.Gull, H.Raza, R.Saeed, <strong>T. Shehzadi</strong>
                        <br>
                        <em>International Review of Applied Sciences and Engineering (IRASE)</em>, 2021
                        <br>
                        <a href="https://akjournals.com/view/journals/1848/15/2/article-p171.xml">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/Protein-Pred.png" alt="protein">
                      </td>
                      <td>
                        <papertitle>Protein Active Site Prediction for Early Drug Discovery and Designing</papertitle>
                        A.Yousaf, <strong>T. Shehzadi</strong>, A.Farooq, Komal Ilyas 
                        <br>
                        <em>International Review of Applied Sciences and Engineering (IRASE)</em>, 2021
                        <br>
                        <a href="https://www.researchgate.net/publication/354444464_Protein_active_site_prediction_for_early_drug_discovery_and_designing">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

                <div class="paper">
                  <table>
                    <tr>
                      <td>
                        <img src="figures/Cancer-pred.png" alt="Cancer-Pred">
                      </td>
                      <td>
                        <papertitle>Intelligent predictor using cancer-related biologically information extraction from cancer transcriptomes</papertitle>
                        <strong>T. Shehzadi</strong>, A.Majid, M.Hameed, A.Farooq, A.Yousaf
                        <br>
                        <em>Recent Advances in Electrical Engineering & Computer Sciences (RAEE & CS)</em>, 2020
                        <br>
                        <a href="https://ieeexplore.ieee.org/document/9265692">Paper</a> 
                      </td>
                    </tr>
                  </table>
                </div>

              
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr id="services">
              <td style="padding:20px;width:100%;vertical-align:middle">
                <span class="section">Services</span>
                <p class="bio">
                  <strong>Reviewer of Conferences:</strong><br>
                  ICDAR2025, MIUA2025, WACV2025
                </p>
              </td>
            </tr>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <span class="section">Honors & Awards</span>
                <ul>
                  <li><strong>DAAD Fellowship</strong>: Received PhD Scholarship (2021â€“2026)</li>
                  <li><strong>NSF Travel Grant</strong>: For WiML Workshop at NeurIPS 2024</li>
                  <li><strong>PIEAS Fellowship</strong>: Received merit based full scholarship for complete Masters</li>
                  <li>Nominated for the Two Academic Excellence Medals 2014 in Intermediate Studies</li>
                </ul>
              </td>
            </tr>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <p style="text-align:center;font-size:small;">
                  Template credits: <a href="https://jonbarron.info/">Jon Barron</a>.<br>
                </p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
    </table>
  </body>
</html>


